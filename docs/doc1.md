---
id: doc1
title: Search Introduction
sidebar_label: Search Introduction
---

Next Up: An Introduction to Race and Gender in Spotify Searches

conducted by: Maxine Addo-Kufuor, Adam Bi, Danielle Blevens, Sarah Champ, Anqizi Xu, Benjamin Shi

Introduction:

Spotify is a globally recognized digital music streaming service. Their music library
contains a wide range of music genres that serves to a diverse audience. However, as is the case
with many services, there are limitations that affects how certain users interact with a product.
For instance, white heterosexual men have long been centered and depicted as the “average” user
for many internet services, resulting in the exclusion of people of color, women and queer
identified users. Often times, these underrepresented groups have come across challenges that the
perceived average user would not have been met with. In this study, we explore how gender and
race bias are inserted in Spotify’s search results. Understanding gender and race in relation to
technology allows one to grasp a deeper understanding of data classification and accessibility.
Centering gender and race in technology can reveal a lot about the root causes of biased data.

To begin with, focusing on Spotify’s intersection with gender gives us interesting insights
into how its developers understand themes such as gender and sexuality. For one, although this is
more often and more obvious in the case of dating apps, many social media platforms
demonstrate that they do not design with queer users in mind. On apps such as Tinder, queer
users have dealt with the challenges of being matched with heterosexual users or encountering
fake profiles. In Queer women’s experiences of patchwork platform governance on Tinder,
Instagram, and Vine, a study was conducted to examine queer women’s relationship to social
media platforms. The study dives into the shortcomings of platforms such as the aforementioned,
finding that the biases that feed these platforms shape the experiences of those who use them.
They addressed, for instance, the failure of governance on Tinder due to queer women being
matched with men hiding behind female profiles (Burgess, Duguay & Suzay, 2018). Another
example of algorithmic biases, more specific to our own topic, is seen with Spotify’s default
country music playlist. In September of 2019, country artist Martina McBride spoke out against
Spotify for their lack of female representation in their country music playlist (Dredge, 2019).
McBride expressed disappointment when discovering the over representation of male country
artists on the application. The erasure of female artists in the country music playlists, speaks to
the larger issue of country music’s association with masculinity. Despite women’s contribution
to country music, it is known that the genre is male dominated. Spotify’s algorithm mirrors this
gender imbalance, by hindering female artists from being being streamed. In turn, as we conduct
our study, we will explore the gender-based limitations a specific user will come across as they
use Spotify and how it reflects on social norms.

Likewise, a close examination at apps within the social media space also helps us to
understand how racially charged biases manifest within the services used by millions across
diverse demographics every day. In much the same vein as many services’ tendencies to imagine
their default users as heterosexual men, the intended users of an app are oftentimes subtly
shown--whether through images or through implicit language--to be primarily white. Although
many apps and services today mention a commitment to “diversity”, the methodology through
which they demonstrate such a commitment oftentimes ignore the cultural differences that are
inherently tied to race, suggesting that white people are the default audience while others are
either an afterthought or a ‘special’ class. For instance, even before going too much in detail on
our study of Spotify, the meer existence of preset playlists such as “Black History Month” and
“Korean Pop” suggest that these are playlists catered to special interest groups, while the lack of
any corresponding playlist with “White” in its name suggests that white people are in fact
already accounted for as the default for everything else. Throughout our study on the racial
elements displayed within a user’s experience with the Spotify app, thus, we will detail the subtle
implications made by Spotify’s structure on the topic of racial biases.

Moving on to the app itself, one immediately then encounters the first step in Spotify’s
algorithms for data collection and categorization. Upon first launching the app or online site,
users find themselves required by Spotify to fill in their personal information before proceeding
onto their application. The three options for “gender” are male, female, and non-binary. There is
no field for race at all. Our research will thus explore a combination of how Spotify’s search
feature yields distinct results based on gender identity, and also on how race modifies this
experience in a space where users do not input their race to begin with. The study will take an indepth look at how user interaction is based on a user’s recorded information. The design plan requires our team to create accounts made under different gender identities, leaving race
ambiguous since there is no way to modify it. The users will then enter specific search topics
and analyze the results displayed in their search results. We will evaluate how Spotify’s
algorithms cater to a specific audience, and the limitations that non-male, non-heterosexual, and
non-white users will come across when using the service.

Putting all these themes together, we hope to continue a line of research undertaken by
numerous leading scholars who work on revealing the hidden biases behind the seemingly
‘neutral’ apps behind our everyday experiences. In Algorithms’ of Oppression, for example,
Safiya Noble discusses how discrimination is entwined in software. The book highlights how
marginalized people have been misrepresented in Google’s search results (Noble, 2018, pg.4).
Noble addresses the pervasiveness of racism and sexism, and her work guides us to better
understand how search results narrow and distort information. Sexism, gender bias, and racism in
technology are widely discussed topics, and many researchers like Noble have found that
designers and engineers take on extremely biased approaches when developing applications
within the tech space. Given that technology is a white-male dominated field, it is not surprising
that even up-and-coming technologies such as artificial intelligence perpetuate gender and race
biases in a time when society tries so hard to label itself as inclusive and progressive. Through
our examination of the user experiences offered by Spotify’s app, we hope to bring to light how
some of these biases hide themselves behind the curtain of an assumption of neutrality. More
specifically, through our exploration of Spotify’s platform, we want to see how our gender
identity affects the search results we are given, as well as how our demonstrated interest in racespecific genres affects the racial elements of the music recommendations Spotify then gives us.

Picture taken from Spotify’s own home page, at spotify.me/en. Are we what we stream, or do
we stream what we are (according to Spotify)?

Research Team:
Our research team consists of students with different interests and who are studying a
variety of majors, such as Education, Communication, Informatics, Political Science, Economics,
Geographic Information Systems (GIS), and Community, Environment, and Planning (CEP).
Our research team is also diverse in demographic background, with a combination of diverse
personal experiences and access to diverse groups of others who can be interviewed or studied
across lines of race and gender. Our team’s identities and backgrounds ensures that throughout
the project, different viewpoints and perspectives are not only being voiced, but also constantly
interrogated. This has been demonstrated in our brainstorming sessions and planning, as
members of our team have drawn upon one’s own experience and have told individual narratives
to contribute to the direction and research of our project. It is critical to have diversity in a team
to understand and shed light upon issues and obstacles that face different communities. For this
project in particular, diversity has allowed for a greater collaboration of ideas to exist and has
made our research team empathetic to issues that underrepresented groups face regarding
technology.

Our systems have historically been created by and thus catered for white men, which has
consistently placed other underrepresented groups at a disadvantage in our society. Without
diversity, systems have been coded for and have pushed not only sexist narratives but also racist
ones, as noted by Noble in Algorithms of Oppression. Noble demonstrates that algorithms can
reinforce biases due to search terms--an important focus that our study will also draw from.
Through describing the story of Dylann Roof and his “black on white crime” Google search
inquires, for example, she determines that search engines often oversimplify complex
phenomena. As Janet Abbate, another prominent researcher in the space, notes, “[search results]
obscure any struggle over understanding, and they can mask history” (Abbate, 2012, p.116).
Framing a question in search inquiries has been shown to lead people to racist and sexist search
results, which demonstrates the importance of having a diverse representation within the group
of programmers who create apps for others to use. To us, this signals that it is imperative that we
harness our nuanced perceptions of race and gender in order to dissect the ways that Spotify
engages our identities and the identities of others.

The Walkthrough Method:

The walkthrough method, as outlined and detailed by Jean Burgess, Ben Light, and
Stefanie Duguay, aids researchers in critically examining apps by giving a framework to analyze
the product and it’s intended use. By using the walkthrough method, researchers are able to
establish different user cases and perform a step-by-step technical walkthrough of an app
consisting of the user’s initial registration, everyday use, as well as discontinuation of use. The
walkthrough method helps researchers delve into the potential complexity and hidden uses of an
app as well, while helping identify cultural implications as well as the app’s intended users and
scenarios. The method involves an analysis of the “environment of expected use”, where an
app’s vision or purpose is identified, and is the basis for comparing the app’s aesthetics and
specific user flow, which may lead a user towards a specific goal or search result (Burgess et al.,
2016). Through the technical walkthrough, researchers physically use the app to determine
specific mechanisms and the flow of designated activities. Screenshots are recorded of the
process, which allows for researchers to visually display and communicate their findings in an
effective way. By physically using the app, functionality can be critically analyzed and can
reveal how features of an app can guide or limit a user’s actions. Furthermore, physical use of
the app can elicit certain responses or feelings from the user, which simple theoretical
understandings of an app might not be able to access.

The walkthrough method is appropriate for our research team’s purposes, as our team
will focus on how race and gender may affect a user’s result using the search feature on Spotify.
The method is ideal for the scope of our research, as we wish to analyze how Spotify may guide
a user by displaying search results based upon one’s recorded profile in the app. By performing a
technical walkthrough, we can critically identify the functionality of Spotify through the lens of a
female, male, as well as a non-binary person, while studying the racial implications through a
more ambiguous scope (since the app does not record our race as part of our initial profile). Our
team will study the technology service primarily via its iOS app. We plan on collecting data over
the course of several days to determine if search results change over time, and our research team
plans on comparing multiple short-term accounts. We wish to focus on newly created accounts,
as search results within long-term accounts would likely differ due to demonstrated user
preferences. Our team will also analyze how the default suggestions given to the user from
Spotify are altered depending on the user’s gender.

Our search terms include: “cleaning music”, “love songs”, “get ready music”, “rap
music” “workout music”, “rock music”, and “country music”. Our team plans on searching these
terms across our different user cases, which includes different gendered accounts, to observe
how search results may change depending on the user’s gender. Then, to study racial biases
demonstrated by the app, our team will look through features such as playlists that imply a racial
theme, for instance: “K-pop”, “Regional Mexican”, “Reggae”, “Black history is now”, “Afro”.
To supplement our findings in this regard, we will have one user account carefully demonstrate
an interest in music from black artists, before glancing at the “Made For You” sections in the app
to record how race might play a part (whether implicitly or explicitly) in the algorithms that
serve us curated music recommendations. We will then compare this to another user who
demonstrates interest in white artists only. By looking at all of these findings together, we hope
to create a detailed analysis of how race and gender stereotypes play a role in Spotify’s
interactions with its 217 million users worldwide.
References:

Abbate, J. (2012). Recoding Gender: Women’s Changing Participation in Computing. Retrieved
from http://ebookcentral.proquest.com/lib/washington/detail.action?docID=3339524

Burgess, J., & Duguay S., & Light B. (2016). The walkthrough method: An approach to the
study of apps. Sage Journals. https://doi.org/10.1177/1461444816675438

Duguay, S., Burgess, J., & Suzor, N. (2018). Queer women’s experiences of patchwork platform
governance on Tinder, Instagram, and Vine. Convergence: The International Journal of
Research into New Media Technologies

Noble, S. U. (2018). Algorithms of oppression: how search engines reinforce racism. New York:
New York University Press.
